{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88ef4b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in ./environment/lib/python3.8/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in ./environment/lib/python3.8/site-packages (from openpyxl) (2.0.0)\n",
      "\u001b[33mWARNING: Error parsing dependencies of bleach: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
      "    tinycss2 (>=1.1.0<1.2) ; extra == 'css'\n",
      "             ~~~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: xlrd in ./environment/lib/python3.8/site-packages (2.0.1)\n",
      "\u001b[33mWARNING: Error parsing dependencies of bleach: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
      "    tinycss2 (>=1.1.0<1.2) ; extra == 'css'\n",
      "             ~~~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "!{sys.executable} -m pip install openpyxl\n",
    "!{sys.executable} -m pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91a77f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in ./environment/lib/python3.8/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in ./environment/lib/python3.8/site-packages (from openpyxl) (2.0.0)\n",
      "\u001b[33mWARNING: Error parsing dependencies of bleach: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
      "    tinycss2 (>=1.1.0<1.2) ; extra == 'css'\n",
      "             ~~~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: xlrd in ./environment/lib/python3.8/site-packages (2.0.1)\n",
      "\u001b[33mWARNING: Error parsing dependencies of bleach: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
      "    tinycss2 (>=1.1.0<1.2) ; extra == 'css'\n",
      "             ~~~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0mIndex(['Lemma', 'Pos', 'Points'], dtype='object')\n",
      "              word cefr_level\n",
      "5339       liquido         C2\n",
      "5340   raggruppare         C2\n",
      "5341        ridare         C2\n",
      "5342    ospitalità         C2\n",
      "5343      pomodoro         C2\n",
      "5344     pescatore         C2\n",
      "5345    chirurgico         C2\n",
      "5346  implementare         C2\n",
      "5347         umore         C2\n",
      "5348    subentrare         C2\n",
      "✅ Saved full CEFR vocabulary to 'italian_cefr_from_kelly_full.csv'\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the full Kelly Project Italian dataset\n",
    "# Download from: https://ssharoff.github.io/kelly/\n",
    "# Use the Italian file: \"itfull.csv\" or \"kelly_italian.csv\"\n",
    "df = pd.read_excel(\"it_m3.xls\")\n",
    "\n",
    "# Step 2: Inspect available columns (uncomment to preview)\n",
    "print(df.columns)\n",
    "#print(df.head(10))\n",
    "\n",
    "# Step 3: Define mapping from Points to CEFR levels\n",
    "points_to_cefr = {\n",
    "    1: \"A1\",\n",
    "    2: \"A2\",\n",
    "    3: \"B1\",\n",
    "    4: \"B2\",\n",
    "    5: \"C1\",\n",
    "    6: \"C2\"\n",
    "}\n",
    "\n",
    "# Step 4: Apply CEFR mapping\n",
    "#df[\"cefr_level\"] = df[\"Points\"].map(points_to_cefr)\n",
    "df[\"cefr_level\"] = df[\"Points\"]\n",
    "\n",
    "# Step 5: Filter relevant columns\n",
    "df_cefr = df[[\"Lemma\", \"cefr_level\"]].rename(columns={\"Lemma\": \"word\"})\n",
    "\n",
    "# Step 6: Drop rows with missing CEFR level\n",
    "df_cefr = df_cefr.dropna(subset=[\"cefr_level\"])\n",
    "print(df_cefr.tail(10))\n",
    "\n",
    "# Step 7: Save to CSV\n",
    "df_cefr.to_csv(\"italian_cefr_from_kelly_full.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved full CEFR vocabulary to 'italian_cefr_from_kelly_full.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1d24a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged CEFR + frequency list saved to 'italian_cefr_vocab_with_freq.csv'\n"
     ]
    }
   ],
   "source": [
    "# Load CEFR-tagged word list (output from Kelly Project)\n",
    "df_cefr = pd.read_csv(\"italian_cefr_from_kelly_full.csv\")\n",
    "\n",
    "# Load HermitDave frequency list (format: word frequency)\n",
    "df_freq = pd.read_csv(\"italian_freq.txt\", sep=\" \", names=[\"word\", \"frequency\"])\n",
    "\n",
    "# Optional: normalize word column\n",
    "df_cefr[\"word\"] = df_cefr[\"word\"].str.lower()\n",
    "df_freq[\"word\"] = df_freq[\"word\"].str.lower()\n",
    "\n",
    "# Merge on 'word'\n",
    "merged_df = pd.merge(df_cefr, df_freq, on=\"word\", how=\"left\")\n",
    "\n",
    "# Optional: Drop words without frequency info (or fill with default)\n",
    "merged_df = merged_df.dropna(subset=[\"frequency\"])\n",
    "\n",
    "# Sort by CEFR level and frequency (higher frequency = lower rank number)\n",
    "merged_df = merged_df.sort_values(by=[\"cefr_level\", \"frequency\"], ascending=[True, False])\n",
    "\n",
    "# Save final output\n",
    "merged_df.to_csv(\"italian_cefr_vocab_with_freq.csv\", index=False)\n",
    "\n",
    "print(\"✅ Merged CEFR + frequency list saved to 'italian_cefr_vocab_with_freq.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ab891c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab_data(path=\"italian_cefr_vocab_with_freq.csv\"):\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"word\"] = df[\"lemma\"].str.lower()\n",
    "    return df\n",
    "\n",
    "def recommend_words(user_known_words, user_cefr_level, vocab_df, top_n=20):\n",
    "    # Define CEFR progression\n",
    "    cefr_order = [\"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\"]\n",
    "    level_index = cefr_order.index(user_cefr_level)\n",
    "    target_levels = cefr_order[max(0, level_index):min(len(cefr_order), level_index + 2)]\n",
    "\n",
    "    # Filter by CEFR level and remove known words\n",
    "    filtered = vocab_df[\n",
    "        (vocab_df[\"cefr_level\"].isin(target_levels)) &\n",
    "        (~vocab_df[\"word\"].isin(user_known_words))\n",
    "    ]\n",
    "\n",
    "    # Sort by frequency descending (most common first)\n",
    "    filtered = filtered.sort_values(by=\"frequency\", ascending=False)\n",
    "\n",
    "    return filtered.head(top_n)[[\"word\", \"cefr_level\", \"frequency\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77b87f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        word cefr_level  frequency\n",
      "1984    cosa         B1  1462858.0\n",
      "2947      no         B2  1433410.0\n",
      "1985     mio         B1   752241.0\n",
      "2948   tutto         B2   704866.0\n",
      "1986     era         B1   657610.0\n",
      "2949   detto         B2   530015.0\n",
      "1987   molto         B1   430250.0\n",
      "2950  perché         B2   417508.0\n",
      "2951   prima         B2   387026.0\n",
      "1988     suo         B1   381756.0\n"
     ]
    }
   ],
   "source": [
    "# Load vocab data\n",
    "vocab_df = load_vocab_data()\n",
    "\n",
    "# Example user profile\n",
    "user_known_words = {\"essere\", \"avere\", \"fare\", \"dire\", \"andare\", \"parlare\"}\n",
    "user_cefr_level = \"B1\"\n",
    "\n",
    "# Get recommendations\n",
    "recommendations = recommend_words(user_known_words, user_cefr_level, vocab_df, top_n=10)\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b248159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Lemma', 'Pos', 'Points', 'word'], dtype='object')\n",
      "✅ Updated file saved as 'italian_cefr_vocab_with_freq_pos.csv'\n"
     ]
    }
   ],
   "source": [
    "# Load your main vocabulary file (without POS or outdated POS)\n",
    "main_df = pd.read_csv(\"italian_cefr_vocab_with_freq.csv\")\n",
    "main_df[\"word\"] = main_df[\"word\"].str.lower()\n",
    "\n",
    "# Load the source Excel file that contains the correct POS info\n",
    "# Adjust the sheet name or columns if needed\n",
    "source_df = pd.read_excel(\"it_m3.xls\")\n",
    "source_df[\"word\"] = source_df[\"Lemma\"].str.lower()\n",
    "\n",
    "# Inspect columns to identify the correct POS column\n",
    "print(source_df.columns)\n",
    "\n",
    "# Merge on 'word' column, keeping POS from source\n",
    "merged_df = pd.merge(main_df, source_df[[\"word\", \"Pos\"]], on=\"word\", how=\"left\")\n",
    "\n",
    "# Save the updated file\n",
    "merged_df.to_csv(\"italian_cefr_vocab_with_freq_pos.csv\", index=False)\n",
    "\n",
    "print(\"✅ Updated file saved as 'italian_cefr_vocab_with_freq_pos.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
